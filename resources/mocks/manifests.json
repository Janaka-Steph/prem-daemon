[
    {
        "id": "chat-mock-small",
        "name": "Chat Mock Small",
        "icon": "",
        "description": "Hello World.",
        "documentation": "Hello World",
        "modelInfo": {
            "maxLength": 12000,
            "tokenLimit": 4000,
            "weightsSize": 4212859520,
            "memoryRequirements": 8192,
            "inferenceTime": "5 tokens per second",
            "streaming": true
        },
        "interfaces": [
            "chat",
            "embeddings"
        ],
        "dockerImages": {
            "cpu": {
                "size": 145095981,
                "image": "ghcr.io/premai-io/chat-mock-small:0.0.1"
            }
        },
        "defaultPort": 8000,
        "defaultExternalPort": 8001
    },
    {
        "id": "chat-mock-medium",
        "name": "Chat Mock Medium",
        "icon": "",
        "description": "Hello World.",
        "documentation": "Hello World",
        "modelInfo": {
            "maxLength": 12000,
            "tokenLimit": 4000,
            "weightsSize": 4212859520,
            "memoryRequirements": 12288,
            "inferenceTime": "5 tokens per second"
        },
        "interfaces": [
            "chat",
            "embeddings"
        ],
        "dockerImages": {
            "cpu": {
                "size": 145095981,
                "image": "ghcr.io/premai-io/chat-mock-medium:0.0.1"
            }
        },
        "defaultPort": 8000,
        "defaultExternalPort": 8001
    },
    {
        "id": "chat-mock-large",
        "name": "Chat Mock Large",
        "icon": "",
        "description": "Hello World.",
        "documentation": "Hello World",
        "modelInfo": {
            "maxLength": 12000,
            "tokenLimit": 4000,
            "weightsSize": 4212859520,
            "memoryRequirements": 102400,
            "inferenceTime": "5 tokens per second"
        },
        "interfaces": [
            "chat",
            "embeddings"
        ],
        "dockerImages": {
            "cpu": {
                "size": 145095981,
                "image": "ghcr.io/premai-io/chat-mock-large:0.0.1"
            }
        },
        "defaultPort": 8000,
        "defaultExternalPort": 8001
    },
    {
        "id": "embeddings-mock-small",
        "name": "Embeddings Mock Small",
        "icon": "",
        "description": "Hello World.",
        "documentation": "Hello World",
        "modelInfo": {
            "maxLength": 12000,
            "tokenLimit": 4000,
            "weightsSize": 4212859520,
            "memoryRequirements": 8192,
            "inferenceTime": "5 tokens per second"
        },
        "interfaces": [
            "embeddings"
        ],
        "dockerImages": {
            "cpu": {
                "size": 145095981,
                "image": "ghcr.io/premai-io/embeddings-mock-small:0.0.1"
            }
        },
        "defaultPort": 8000,
        "defaultExternalPort": 8001
    },
    {
        "id": "embeddings-mock-medium",
        "name": "Embeddings Mock Medium",
        "icon": "",
        "description": "Hello World.",
        "documentation": "Hello World",
        "modelInfo": {
            "maxLength": 12000,
            "tokenLimit": 4000,
            "weightsSize": 4212859520,
            "memoryRequirements": 12288,
            "inferenceTime": "5 tokens per second"
        },
        "interfaces": [
            "embeddings"
        ],
        "dockerImages": {
            "cpu": {
                "size": 145095981,
                "image": "ghcr.io/premai-io/embeddings-mock-medium:0.0.1"
            }
        },
        "defaultPort": 8000,
        "defaultExternalPort": 8001
    },
    {
        "id": "embeddings-mock-large",
        "name": "Embeddings Mock Large",
        "icon": "",
        "description": "Hello World.",
        "documentation": "Hello World",
        "modelInfo": {
            "maxLength": 12000,
            "tokenLimit": 4000,
            "weightsSize": 4212859520,
            "memoryRequirements": 102400,
            "inferenceTime": "5 tokens per second"
        },
        "interfaces": [
            "embeddings"
        ],
        "dockerImages": {
            "cpu": {
                "size": 145095981,
                "image": "ghcr.io/premai-io/embeddings-mock-large:0.0.1"
            }
        },
        "defaultPort": 8000,
        "defaultExternalPort": 8001
    },
    {
        "id": "qdrant",
        "name": "Qdrant",
        "description": "Qdrant is a vector similarity search engine designed for storing, searching, and managing points along with their respective payloads. Built with an emphasis on extensive filtering, it is particularly beneficial for neural network matching, semantic-based matching, and faceted search. Qdrant offers various deployment options including local mode, on-premise server deployment, and Qdrant Cloud, each catering to different use-case scenarios. [Learn More](https://qdrant.tech/documentation/)",
        "documentation": "<h1>Documentation</h1>\n<h2>Description</h2>\n<p>Qdrant is a vector similarity search engine designed for storing, searching, and managing points along with their respective payloads. Built with an emphasis on extensive filtering, it is particularly beneficial for neural network matching, semantic-based matching, and faceted search. Qdrant offers various deployment options including local mode, on-premise server deployment, and Qdrant Cloud, each catering to different use-case scenarios. <a href=\"https://qdrant.tech/documentation/\">Learn More</a></p>\n<h2>Hardware Requirements</h2>\n<h2>Example Usage</h2>\n<h2>Fine Tuning Instructions &amp; Cost</h2>\n<h2>Inference Benchmarks</h2>",
        "interfaces": [
            "store"
        ],
        "icon": "https://raw.githubusercontent.com/premAI-io/prem-registry/main/store-qdrant/logo.svg",
        "modelInfo": {},
        "dockerImages": {
            "cpu": {
                "size": 126913893,
                "image": "qdrant/qdrant:v1.0.3"
            }
        },
        "defaultPort": 6333,
        "defaultExternalPort": 6333
    },
    {
        "id": "redis",
        "name": "Redis",
        "description": "Redis, short for Remote Dictionary Server, serves as a multifunctional in-memory data structure store. It functions as a distributed key-value database, cache, and message broker, all operating in-memory for high-speed data access. With optional durability, Redis ensures data persistence despite potential system failures. [Learn More](https://redis.com/solutions/use-cases/vector-database/)",
        "documentation": "<h1>Documentation</h1>\n<h2>Description</h2>\n<p>Redis, short for Remote Dictionary Server, serves as a multifunctional in-memory data structure store. It functions as a distributed key-value database, cache, and message broker, all operating in-memory for high-speed data access. With optional durability, Redis ensures data persistence despite potential system failures. <a href=\"https://redis.com/solutions/use-cases/vector-database/\">Learn More</a></p>\n<h2>Hardware Requirements</h2>\n<h2>Example Usage</h2>\n<h2>Fine Tuning Instructions &amp; Cost</h2>\n<h2>Inference Benchmarks</h2>",
        "interfaces": [
            "store"
        ],
        "icon": "https://raw.githubusercontent.com/premAI-io/prem-registry/main/store-redis/logo.svg",
        "modelInfo": {},
        "dockerImages": {
            "cpu": {
                "size": 261514099,
                "image": "redis/redis-stack-server:latest"
            }
        },
        "defaultPort": 6379,
        "defaultExternalPort": 6379
    }
]
